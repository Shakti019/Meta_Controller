# MetaController - Industrial Machine Management Platform

AI-powered digital twin platform for industrial machine monitoring, fault detection, and workload optimization using ONNX machine learning models.

## ğŸ¯ Features

- **Machine CRUD Management**: Add, edit, delete machines with full sensor configuration
- **Digital Twin Simulator**: Real-time physics-based machine behavior simulation
- **ML Decision Engine**: 4 ONNX models for fault detection, load forecasting, and optimization
- **Control Center**: Start/stop machines, manage workloads, real-time monitoring
- **Analytics Dashboard**: Efficiency trends, fault history, optimization savings
- **Role-Based Access**: Admin, Engineer, Operator, Viewer permissions

## ğŸ§  ML Models (ONNX Runtime Web)

| Model | Purpose | Input | Output |
|-------|---------|-------|--------|
| **LSTM Digital Twin** | Predict next machine state | 10Ã—5 sensor sequence | Vibration, Temperature |
| **Autoencoder** | Anomaly detection | Vibration, Current, Temp | Reconstruction error |
| **GRU Load Forecast** | Future load prediction | 24 historical load values | Next load value |
| **DQN Agent** | Workload optimization | State (vib, temp, load) | Action (â†“/hold/â†‘) |

## ğŸ“¦ Setup

### 1. Install Dependencies

```bash
cd MetaController
npm install
```

### 2. Copy ONNX Models

Copy the 4 `.onnx` files to `public/models/`:

```bash
# From parent directory
cp ../lstm_digital_twin.onnx public/models/
cp ../dqn_agent.onnx public/models/
cp ../autoencoder_anomaly.onnx public/models/
cp ../gru_load_forecast.onnx public/models/
```

### 3. Run Development Server

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000)

## ğŸš€ Deploy to Vercel

### Option 1: Vercel CLI

```bash
npm install -g vercel
vercel
```

### Option 2: GitHub Integration

1. Push code to GitHub
2. Import repository in Vercel dashboard
3. Set environment variables (if needed)
4. Deploy

### Environment Variables

Create `.env.local`:

```env
# Optional: MongoDB for production
MONGODB_URI=mongodb+srv://...

# Optional: Authentication
NEXTAUTH_URL=http://localhost:3000
NEXTAUTH_SECRET=your-secret-key

# Optional: Vercel KV for caching
KV_REST_API_URL=...
KV_REST_API_TOKEN=...
```

## ğŸ“ Project Structure

```
MetaController/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx              # Home/Dashboard
â”‚   â”œâ”€â”€ layout.tsx            # Root layout
â”‚   â”œâ”€â”€ machines/             # Machine management
â”‚   â”œâ”€â”€ simulator/            # Digital twin
â”‚   â”œâ”€â”€ analytics/            # Reports & insights
â”‚   â””â”€â”€ api/                  # API routes
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ onnx/
â”‚   â”‚   â”œâ”€â”€ modelLoader.ts    # ONNX session management
â”‚   â”‚   â””â”€â”€ inference.ts      # ML prediction wrappers
â”‚   â”œâ”€â”€ simulator.ts          # Physics engine
â”‚   â””â”€â”€ decision-engine.ts    # ML orchestration
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/                   # Reusable UI components
â”‚   â”œâ”€â”€ charts/               # Data visualization
â”‚   â””â”€â”€ control/              # Machine controls
â””â”€â”€ public/
    â””â”€â”€ models/               # ONNX model files
        â”œâ”€â”€ lstm_digital_twin.onnx
        â”œâ”€â”€ dqn_agent.onnx
        â”œâ”€â”€ autoencoder_anomaly.onnx
        â”œâ”€â”€ gru_load_forecast.onnx
        â””â”€â”€ model_metadata.json
```

## ğŸ”Œ API Routes

### Machines
- `GET /api/machines` - List all machines
- `POST /api/machines` - Create machine
- `GET /api/machines/[id]` - Get machine details
- `PUT /api/machines/[id]` - Update machine
- `DELETE /api/machines/[id]` - Delete machine

### Simulation
- `GET /api/simulator/start` - Start digital twin
- `GET /api/simulator/stop` - Stop simulation
- `WS /api/simulator/stream` - WebSocket sensor stream

### ML Inference
- `POST /api/ml/predict-state` - LSTM prediction
- `POST /api/ml/detect-anomaly` - Autoencoder check
- `POST /api/ml/forecast-load` - GRU forecast
- `POST /api/ml/optimize-load` - DQN action

## ğŸ¨ Technology Stack

- **Framework**: Next.js 14 (App Router)
- **Language**: TypeScript
- **Styling**: Tailwind CSS
- **ML Runtime**: ONNX Runtime Web
- **Charts**: Recharts / Chart.js
- **Real-time**: Socket.IO
- **Auth**: NextAuth.js
- **Database**: MongoDB Atlas (optional)
- **Deployment**: Vercel

## ğŸ“Š Usage Examples

### Predict Next Machine State

```typescript
import { predictNextState } from '@/lib/onnx/inference';

const sensorHistory = [
  { rpm: 1000, load_percent: 50, load_kw: 25, current: 0.5, torque: 20 },
  // ... last 10 readings
];

const prediction = await predictNextState(sensorHistory);
console.log(prediction); // { vibration: 10.2, temperature: 42.5 }
```

### Detect Anomaly

```typescript
import { detectAnomaly } from '@/lib/onnx/inference';

const result = await detectAnomaly({
  vibration: 12.5,
  current: 0.8,
  temperature: 45
});

if (result.isAnomaly) {
  console.log('âš ï¸ Fault detected!');
}
```

### Optimize Workload

```typescript
import { optimizeLoad } from '@/lib/onnx/inference';

const action = await optimizeLoad({
  vibration: 10,
  temperature: 40,
  load_kw: 30
});

console.log(`Recommended: ${action.action}`); // "hold_load"
```

## ğŸ§ª Testing

Run ONNX inference tests:

```bash
npm run test:ml
```

## ğŸ“ Model Preprocessing

All inputs are Min-Max scaled (0-1). Ensure consistency:

- **Vibration**: 5-15 range
- **Temperature**: 30-50Â°C range
- **Load**: 0-50 kW range
- **Current**: 0-1 A range
- **RPM**: 500-1500 range

## ğŸ› ï¸ Troubleshooting

### ONNX Model Load Error
- Verify `.onnx` files are in `public/models/`
- Check browser console for CORS issues
- Ensure WASM is enabled in browser

### WebSocket Connection Failed
- Check firewall/proxy settings
- Verify Socket.IO client version matches server

### Build Errors
- Clear `.next` folder: `rm -rf .next`
- Reinstall: `rm -rf node_modules && npm install`

## ğŸ“„ License

MIT

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Open Pull Request

---

Built with â¤ï¸ using Next.js, ONNX Runtime, and TensorFlow
